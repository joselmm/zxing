<!doctype html>
<html lang="es">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ZXing - crop area example</title>
  <style>
    body {
      font-family: system-ui, Arial;
      margin: 1rem
    }

    .video-wrap {
      position: relative;
      max-width: 900px;
      margin: 0 auto;
    }

    video {
      width: 100%;
      height: 100px;
      display: block;
      background: #000;
      object-fit: cover;
    }

    /* overlay (scan area) */
    .scan-area {
      position: absolute;
      width: 50%;
      /* tamaño relativo al vídeo (ajusta aquí) */
      height: 28%;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -50%);
      border: 3px dashed rgba(0, 255, 0, 0.9);
      box-shadow: 0 0 12px rgba(0, 255, 0, 0.15);
      pointer-events: none;
      box-sizing: border-box;
    }

    #result {
      font-size: 1.25rem;
      margin-top: 1rem;
      word-break: break-word
    }

    .controls {
      margin-top: 1rem;
      display: flex;
      gap: 0.5rem
    }
  </style>
</head>

<body>

  <h2>Escanear sólo un área (crop) con ZXing</h2>

  <div class="video-wrap" id="videoWrap">
    <video id="video" playsinline></video>
    <div class="scan-area" id="scanArea"></div>
  </div>

  <div class="controls">
    <button id="startBtn">Start</button>
    <button id="stopBtn" disabled>Stop</button>
    <button id="resetBtn">Reset</button>
  </div>
  <label style="margin-left:0.5rem">
    Efecto:
    <select id="effectMode">
      <option value="none">Original</option>
      <option value="adaptive">Adaptive B/W</option>
      <option value="magic">Magic Color</option>
    </select>
  </label>
  <label style="margin-left:0.5rem">
    <input type="checkbox" id="useProcessedForDecode" />
    Usar procesado para ZXing
  </label>

  <!-- preview pequeño del resultado procesado -->
  <canvas id="processedCanvas" style="display:block; max-width:300px; margin-top:.5rem; border:1px solid #ccc"></canvas>


  <label>Resultado:</label>
  <pre id="result"></pre>




  <!-- ZXing browser (incluye decodeFromCanvas) -->
  <script src="https://unpkg.com/@zxing/browser@latest"></script>
  <script>
    window.onOpenCvReady = async function () {
      console.log("OpenCV cargado");
      var barcodeAudio = new Audio("./barcode-audio.ogg");
      const startBtn = document.getElementById('startBtn');
      const stopBtn = document.getElementById('stopBtn');
      const resetBtn = document.getElementById('resetBtn');
      const video = document.getElementById('video');
      const scanArea = document.getElementById('scanArea');
      const resultEl = document.getElementById('result');
      const processedCanvas = document.getElementById('processedCanvas');

      // lector (BrowserMultiFormatReader usa decodeFromCanvas)
      const codeReader = new ZXingBrowser.BrowserMultiFormatReader();

      // canvas offscreen para el crop
      const cropCanvas = document.createElement('canvas');
      const cropCtx = cropCanvas.getContext('2d');

      let stream = null;
      let scanTimer = null;
      const SCAN_INTERVAL_MS = 500; // ajustar para velocidad/CPU

      async function startCamera() {
        stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = stream;
        await video.play();
      }

      function computeCropRect() {
        const videoRect = video.getBoundingClientRect();
        const overlayRect = scanArea.getBoundingClientRect();

        if (!video.videoWidth || !videoRect.width) return null;

        const scaleX = video.videoWidth / videoRect.width;
        const scaleY = video.videoHeight / videoRect.height;

        const sx = Math.max(0, (overlayRect.left - videoRect.left) * scaleX);
        const sy = Math.max(0, (overlayRect.top - videoRect.top) * scaleY);
        const sw = Math.max(1, overlayRect.width * scaleX);
        const sh = Math.max(1, overlayRect.height * scaleY);

        return { sx: Math.floor(sx), sy: Math.floor(sy), sw: Math.floor(sw), sh: Math.floor(sh) };
      }

      // ---------- SCAN: dibuja, procesa, espera paint y luego decodifica ----------
      async function scanOnce() {
        if (video.readyState < 2) return; // no frame listo
        const rect = computeCropRect();
        if (!rect) return;

        const TARGET_WIDTH = 600;
        const scaleDown = Math.min(1, TARGET_WIDTH / rect.sw);
        const canvasW = Math.max(120, Math.floor(rect.sw * scaleDown));
        const canvasH = Math.max(120, Math.floor(rect.sh * scaleDown));

        // dibujar recorte en canvas offscreen
        cropCanvas.width = canvasW;
        cropCanvas.height = canvasH;
        cropCtx.drawImage(video,
          rect.sx, rect.sy, rect.sw, rect.sh,
          0, 0, canvasW, canvasH
        );

        // preparar canvas visible (preview)
        processedCanvas.width = canvasW;
        processedCanvas.height = canvasH;

        const effect = document.getElementById('effectMode').value;
        const useProcessed = document.getElementById('useProcessedForDecode').checked;

        // aplicar efecto (si está disponible), o copiar si no
        try {
          if ((effect === 'adaptive' || effect === 'magic') && typeof cv === 'undefined') {
            // OpenCV no disponible -> fallback a copia
            const ctx = processedCanvas.getContext('2d');
            ctx.clearRect(0, 0, processedCanvas.width, processedCanvas.height);
            ctx.drawImage(cropCanvas, 0, 0);
          } else {
            if (effect === 'adaptive') {
              applyAdaptiveThresholdToCanvas(cropCanvas, processedCanvas, 25, 8);
            } else if (effect === 'magic') {
              applyMagicColorToCanvas(cropCanvas, processedCanvas, 51, 1.15);
            } else {
              const ctx = processedCanvas.getContext('2d');
              ctx.clearRect(0, 0, processedCanvas.width, processedCanvas.height);
              ctx.drawImage(cropCanvas, 0, 0);
            }
          }
        } catch (procErr) {
          console.error('Error aplicando efecto:', procErr);
          // en caso de error, muestra el crop original
          const ctx = processedCanvas.getContext('2d');
          ctx.clearRect(0, 0, processedCanvas.width, processedCanvas.height);
          ctx.drawImage(cropCanvas, 0, 0);
        }

        // ---- IMPORTANTE: espera a la siguiente animación para que el preview se pinte ----
        await new Promise(r => requestAnimationFrame(() => r())); // asegura que processedCanvas ya es visible

        // opcional: muestra texto breve en el preview o en resultEl mientras se decodifica
        // resultEl.textContent = 'Preview mostrado. Decodificando...';

        // Decodificar desde el canvas elegido (processed o crop)
        const canvasForDecode = useProcessed ? processedCanvas : cropCanvas;
        try {
          const result = await codeReader.decodeFromCanvas(canvasForDecode);
          resultEl.textContent = result.text;
          barcodeAudio.play();
          stopScanning();
        } catch (err) {
          // manejo robusto de NotFoundException (como tenías)
          const errName = err && (err.name || (err.constructor && err.constructor.name));
          const notFoundByName = errName === 'NotFoundException' || errName === 'NotFoundExceptionError';
          const notFoundByGlobal = (typeof ZXingBrowser !== 'undefined' && ZXingBrowser.NotFoundException && err instanceof ZXingBrowser.NotFoundException)
            || (typeof ZXing !== 'undefined' && ZXing.NotFoundException && err instanceof ZXing.NotFoundException);
          const isNotFound = notFoundByName || notFoundByGlobal;

          if (!isNotFound) {
            console.error('decode error:', err);
            resultEl.textContent = 'Error: ' + (err && err.message ? err.message : String(err));
          } else {
            // no hay código en este frame -> comportamiento esperado
            // (no sobreescribir el preview, opcional: limpiar resultado si quieres)
            // resultEl.textContent = '';
          }
        }
      }

      function startScanningLoop() {
        if (scanTimer) clearInterval(scanTimer);
        scanTimer = setInterval(() => { scanOnce().catch(e => console.error(e)); }, SCAN_INTERVAL_MS);
        stopBtn.disabled = false;
        startBtn.disabled = true;
      }

      function stopScanning() {
        if (scanTimer) { clearInterval(scanTimer); scanTimer = null; }
        stopBtn.disabled = true;
        startBtn.disabled = false;
      }

      function stopCamera() {
        if (stream) {
          stream.getTracks().forEach(t => t.stop());
          stream = null;
        }
        video.pause();
        video.srcObject = null;
      }

      // botones
      startBtn.addEventListener('click', async () => {
        resultEl.textContent = 'Buscando...';
        try {
          await startCamera();
          startScanningLoop();
        } catch (err) {
          console.error(err);
          resultEl.textContent = 'No se pudo abrir la cámara: ' + err;
        }
      });

      stopBtn.addEventListener('click', () => {
        stopScanning();
      });

      resetBtn.addEventListener('click', () => {
        stopScanning();
        stopCamera();
        resultEl.textContent = '';
        startBtn.disabled = false;
        stopBtn.disabled = true;
      });

      // cleanup on leave
      window.addEventListener('pagehide', () => {
        stopScanning();
        stopCamera();
      });

      // ------------------ HELPERS (OpenCV) ------------------

      function applyAdaptiveThresholdToCanvas(srcCanvas, dstCanvas, blockSize = 25, C = 8) {
        if (!cv || typeof cv === 'undefined') {
          // fallback: copia simple
          const ctx = dstCanvas.getContext('2d');
          ctx.clearRect(0, 0, dstCanvas.width, dstCanvas.height);
          ctx.drawImage(srcCanvas, 0, 0);
          return;
        }
        if (blockSize % 2 === 0) blockSize++;

        let src = cv.imread(srcCanvas); // RGBA
        let gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

        let blur = new cv.Mat();
        cv.GaussianBlur(gray, blur, new cv.Size(3, 3), 0, 0, cv.BORDER_DEFAULT);

        let dst = new cv.Mat();
        cv.adaptiveThreshold(blur, dst, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, blockSize, C);

        cv.imshow(dstCanvas, dst);

        src.delete(); gray.delete(); blur.delete(); dst.delete();
      }

      function applyMagicColorToCanvas(srcCanvas, dstCanvas, blurK = 51, satFactor = 1.15) {
        if (!cv || typeof cv === 'undefined') {
          const ctx = dstCanvas.getContext('2d');
          ctx.clearRect(0, 0, dstCanvas.width, dstCanvas.height);
          ctx.drawImage(srcCanvas, 0, 0);
          return;
        }
        if (blurK % 2 === 0) blurK++;

        let src = cv.imread(srcCanvas);                    // RGBA
        let rgb = new cv.Mat();
        cv.cvtColor(src, rgb, cv.COLOR_RGBA2RGB);         // RGB

        let field = new cv.Mat();
        cv.medianBlur(rgb, field, blurK);

        let src32 = new cv.Mat();
        let field32 = new cv.Mat();
        rgb.convertTo(src32, cv.CV_32F);
        field.convertTo(field32, cv.CV_32F);

        const meanScalar = cv.mean(field); // [r,g,b,a]
        let meanMat = new cv.Mat(src.rows, src.cols, rgb.type(), meanScalar);
        let mean32 = new cv.Mat();
        meanMat.convertTo(mean32, cv.CV_32F);

        let mult = new cv.Mat();
        cv.multiply(src32, mean32, mult);

        let corrected = new cv.Mat();
        cv.divide(mult, field32, corrected);

        let corrected8 = new cv.Mat();
        corrected.convertTo(corrected8, cv.CV_8U);

        // equalize L channel
        let lab = new cv.Mat();
        cv.cvtColor(corrected8, lab, cv.COLOR_RGB2Lab);
        let channels = new cv.MatVector();
        cv.split(lab, channels);
        let L = channels.get(0);
        cv.equalizeHist(L, L);
        channels.set(0, L);
        cv.merge(channels, lab);
        let enhanced = new cv.Mat();
        cv.cvtColor(lab, enhanced, cv.COLOR_Lab2RGB);

        // boost saturation
        let hsv = new cv.Mat();
        cv.cvtColor(enhanced, hsv, cv.COLOR_RGB2HSV);
        let hsvCh = new cv.MatVector();
        cv.split(hsv, hsvCh);
        let S = hsvCh.get(1);
        let S2 = new cv.Mat();
        S.convertTo(S2, cv.CV_8U, satFactor, 0);
        hsvCh.set(1, S2);
        cv.merge(hsvCh, hsv);
        let finalMat = new cv.Mat();
        cv.cvtColor(hsv, finalMat, cv.COLOR_HSV2RGB);

        cv.imshow(dstCanvas, finalMat);

        // cleanup
        src.delete(); rgb.delete(); field.delete();
        src32.delete(); field32.delete(); meanMat.delete(); mean32.delete();
        mult.delete(); corrected.delete(); corrected8.delete();
        lab.delete(); channels.delete(); L.delete(); enhanced.delete();
        hsv.delete(); hsvCh.delete(); S.delete(); S2.delete(); finalMat.delete();
      }

    }; // fin onOpenCvReady
  </script>

  <script async src="opencv.js" onload="window.onOpenCvReady();" type="text/javascript"></script>
</body>

</html>